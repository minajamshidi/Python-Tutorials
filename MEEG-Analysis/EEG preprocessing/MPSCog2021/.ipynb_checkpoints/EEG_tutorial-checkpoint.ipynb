{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG/MEG signal preprocessing\n",
    "\n",
    "#### Max Planck School of Cognition, Methods in Cognitive Neuroscience, June 2021\n",
    "\n",
    "\n",
    "##### Contact: Mina Jamshidi Idaji @ Neurology Dept., MPI CBS, Leipzig, Germany, jamshidi@cbs.mpg.de\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "There are a number of automatic pipelines for denoising EEG/MEG; however, in many cases you should inspect your data manually. Therefore, the objectives of this notebook are:\n",
    "* Getting to know the usual artifacts in EEG/MEG recordings.\n",
    "* Going through a typical manual pipeline for cleaning EEG/MEG data from usual artifacts.\n",
    "* There can be also side objectives for this tutorial: this is a good chance to deepen your Python skills. So, in case you have limited experience with Python, don't worry at all. I tried to explain coding details as well. If you are already familiar with Python, you can skip the \"Coding Detail\" sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this tutorial:\n",
    "\n",
    "* you will explore the MNE Python object Raw, which includes the sensor-space M/EEG data\n",
    "* the following steps of pre-processing are covered in this tutorial: power-line noise cancellation, bad segments and channels\n",
    "\n",
    "### In the next tutorial:\n",
    "* you will learn the ICA artifact rejection\n",
    "* finalizing the EEG pre-processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "There are three main packages that we will use here:\n",
    "* <a href='https://mne.tools/stable/index.html'>MNE Python</a> is an open-source python toolboxes for analysing electrophysiological signals. MNE Python provides the users with very comprehensive tutorials. There is also an active mailing list for it. There, you can ask your questions and the developers actively respond.\n",
    "\n",
    "* The *signal* module of Scipy is the toolbox for signal processing. I would call it a Python version of MATLAB! ;-) To my best of experience, almost all useful signal processing matlab functions are implemented in scipy.signal with similar name and syntax. \n",
    "\n",
    "* Numpy (and Scipy) are the two basic Python packages that you should learn to work with. Numpy is designed for working with matrices in Python. In case you have never worked with Numpy and you are interested to learn it, I have some notebooks on my <a href='https://github.com/minajamshidi/Python-Tutorials/tree/master/Numpy%20tutorials'>GitHub</a>, which could be used as a playground for exploring Numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We use EEG data of LEMON dataset [2], a public dataset collected at MPI CBS. Go <a href=\"https://ftp.gwdg.de/pub/misc/MPI-Leipzig_Mind-Brain-Body-LEMON/\">here</a>, and download data of subject sub-010088 from `EEG_MPILMBB_LEMON > EEG_Raw_BID_ID`. Make a folder in your current directory and name it \"Data\" and then a subforder named \"sub-010088\" inside Data, then copy the data of sub-010088 in it. You should have three files in './Data/sub-010088/': sub-010088.eeg, sub-010088.vhdr, sub-010088.vmrk.\n",
    "\n",
    "The dataset includes resting-state EEG recordings, which consist of 16, inter- leaved, one-minute blocks of eyes-closed (EC) and eyes-open (EO) conditions. In this tutorial, we want to work with EC condition. We will see how we can extract these data segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note #1\n",
    "\n",
    "In this notebook, I have aimed to guide you through the data, from the stage you load it to the last stage where it is cleaned. The notebook is arranged in two sections:\n",
    "\n",
    "* Section 1: *Loading the data: The raw class*\n",
    "\n",
    "When you load data using MNE Python, it is loaded as a Raw object. For those of you who plan to work with such data, I find it crucial to get to know what each of the attributes of a Raw object mean. Therefore, in section 1 we will take a look at some of the most important attributes of the raw object. In the interest of time, I will skip this section in our hands-on session. However, please take your time to go through this section.\n",
    "    \n",
    "* Section 2: Artifacts\n",
    "    \n",
    "In this section, we will see what kind of artifacts are detectable in EEG data and how to clean them. We will go through this section together in the hands-on session. The only exception is the part of the notebook that we extract the eye-closed condition of the data. I'll skip that part in our session. \n",
    "    \n",
    "\n",
    "> Although I'll skip some parts of the notebook in the hands-on session, I kindly ask you to go through them when you work through the tutorial at home. You can collect your questions regarding those parts and ask them in our session. Additionally, you can always contact me via email and ask your questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note #2\n",
    "\n",
    "If you will work with neuroimaging data, at some point you have to work with some programming language. If you find it challenging to write the exercises of this notebook, do not become disappointed: check the links I provided you, google your questions, etc. Although we have provided you with the answers of the exercises, I do encourage you to spend time to complete them by yourself. It may turn out that you have to spend a couple of hours for this tutorial, but based on my experience, I promise you if you do it yourself and try to understand most of the code lines, your next Python-based tutorial experience will be much smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note #3\n",
    "\n",
    "In order to make this notebook a bit simpler, you are provided with a couple of *help function*. These self-written functions can help us to skip the details of how to do some steps. However, I encourage you to take a look at the content of these functions and ask your quesitons if you have any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note #4\n",
    "\n",
    "In order to be able to run interactive matplotlib plots in jupyter hub, we have to set the backend of the matplotlib package to notebook. This can be achieved by:\n",
    "\n",
    "    %matplotlib notebook\n",
    "\n",
    "Note: If you are running the notebook on your local machine, the backend tk is prefered. You can set it by:\n",
    "\n",
    "    %matplotlib tk\n",
    "    \n",
    "In order to go back to inline plotting, you can write:\n",
    "\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "When recording any data (in general), we always record some unwanted signals (known as artifact or noise)  along with the signal of interest. For example: think a microphone that wants to record the voice of a person in a crowded room, this microphone records the voice of the the target person (= the signal of interest) as well of all other voices in the environment (=artifacts), e.g. other people's voice, or the music being played, or the voice of an ambulance that passes the street! Therefore, the first step of signal processing is to clean the recorded data from artifacts: that's called artifact removal or denoising.\n",
    "\n",
    "Artifacts in electrophysiology data can result from biological or environmental sources. Head movement, eye movement, eye blinks and heart activity are examples of biological artifact sources. The most prominent environmental noise is line noise, which is due to power-line: in Europe 50 Hz, in the US 60 Hz. We will inspect these noise sources in our data later.\n",
    "\n",
    "Cleaning data is done by either removing a whole data segment contaminated by noise, or by separating the noise from signal of interest and removing the noise source signal only. We see both cases in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "    \n",
    "#### Coding Detail: Importing Packages\n",
    "In order to be able to use different features of Python, it is necessary to install and import the relevant packages. For example, the package `numpy` can be used to work with matrices in Python. Importing a package is quite simple. We use `import` to import the package and also use `as` to give it a name. Each package has its own functions. To use this functions later in the code, it is necessary to use the following format `np.` + `name of the function`.\n",
    "\n",
    "You may simply import the package by `import [PackageName]`, for example `import numpy`. In this case, the package does not have a *nickname* (e.g. `np`) any more. You should call it by its original name, for example `numpy.[FunctionName]`. We usually do this when the package name is already a short one.\n",
    "There are cases that you want to use a function of a package directly in your code. In such a case, you should import the function directly by writing `from [PackageName] import [FunctionName]`. For example, `from numpy import pi` can be used when you want to use `pi` instead of `np.pi`. This practice is used when you use a function multiple times in your code, or when you do not need all the functions of a package, but only a couple of them. Another example of importing multiple funtions from a package: `from numpy import pi, dot, mean`. We tend to import the whole package; however, a more professional way is to import only the functions that we need - if they are not many. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't have to run this line every time you run this notebook. Do it only the first time you run this notebook.\n",
    "# afterwards, comment this line. As you already see in these comments, by putting # at the beginning of a line\n",
    "# it will be commented.\n",
    "\n",
    "!pip install --user mne # using ! you can avoid using the terminal to install extra packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mne  # MNE Python\n",
    "from os.path import join  # this function is used to build the directories \n",
    "import numpy as np  # numpy is a library for working with matrices\n",
    "import scipy.signal as sp  # scipy.signal implements the signal processing functions\n",
    "# import matplotlib\n",
    "# matplotlib.use('TKAgg')\n",
    "from matplotlib import pyplot as plt  # matplotlib is the most common used package to do plotting in Python\n",
    "from IPython.display import Video, Image\n",
    "import eeg_tutorial_help_functions as hf  # help functions for this tutorial\n",
    "\n",
    "# the backend of matplotlib for plotting interactive plots in jupyter notebook on jupyter hub of GWDG\n",
    "%matplotlib notebook  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data: The raw class\n",
    "\n",
    "In this section we will load the data using MNE Python and get to know some attibutes of  <a href=\"https://mne.tools/dev/generated/mne.io.Raw.html#mne.io.Raw.plot_psd\">Raw</a> class of this package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to read the data. Note that for data of different devices, you may use different functions [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'sub-010088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vhdr_fname = join('./Data', subject, subject + '.vhdr')  # build the directory of the data\n",
    "# vhdr_fname = './Data/' + subject + '/' + subject + '.vhdr'  # this is an alternative to os.path.join\n",
    "\n",
    "raw_orig = mne.io.read_raw_brainvision(vhdr_fname, preload=True)  # load the data\n",
    "print(raw_orig)  # take a look at what we loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: Strings\n",
    "\n",
    "* Strings in Python are surrounded by single quotation marks, or double quotation marks.\n",
    "    * Example: ` 'Hi' ` or ` \"Hi\" `.\n",
    "* Two strings can be combined using the plus operands.\n",
    "    * Example: ` 'Hello' + 'World!' ` results in a single string object ` 'Hello World!' `\n",
    "* A number can be converted to a string using `str()`.\n",
    "    * Example: `str(2)` results in `'2'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous EEG data is loaded as a <a href=\"https://mne.tools/dev/generated/mne.io.Raw.html#mne.io.Raw.plot_psd\">Raw</a> object. If you want to take a closer look at the raw object, try `print(vars(taw_orig))`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars(raw_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: \n",
    "\n",
    "In practice, if you are going to work with Python, you won't use jupyter notebook. You will use one of the available IDEs for Python, e.g. Pycharm. There, you have the possibility to inspect your objects' attributes from graphical interface. Note that, there are also extensions for jupyter notebook for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <a href=\"https://mne.tools/dev/generated/mne.Info.html#mne.Info\">info</a> attribute of raw object includes the important information about the recording. Let's take a closer look at this dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(raw_orig.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the descriptions of some attributes of Info dictiobary:\n",
    "\n",
    "* bads: A list of the names of bad channels.\n",
    "* ch_names: a list of channel names .\n",
    "* chs: A list of dictionaries including the detailed information of the channels.\n",
    "* highpass: Highpass corner frequency in Hertz. Zero indicates a DC recording.\n",
    "* lowpass: Lowpass corner frequency in Hertz.\n",
    "* nchan: number of channels.\n",
    "* sfreq: sampling frequency in Herz. \n",
    "\n",
    "Info is actually a class of MNE. But it behaves like a dictionary. Therefore, you can extract its attribute for example like `raw_orig.info['sfreq']`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "    \n",
    "#### Coding Detail: Dictionaries\n",
    "\n",
    "Among many websites, you can read <a href=\"https://www.geeksforgeeks.org/python-dictionary/\">here</a> or <a href=\"https://realpython.com/python-dicts/\">here</a> to learn what are dictionaries in Python and how to work with them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail:\n",
    "    \n",
    "* You can read the attributes of a class using `.`: for example `info` is an attribute of `raw_orig` and we can read it with `raw_orig.info'. Every \n",
    "\n",
    "* Classes have functions that are directly applied on them using `.`, these function are called methods. For example, you can extract the data matrix of raw object using method `get_data()` by `raw_orig.get_data()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 1**: Looking at `raw_orig.info`, could you explain the rationale of why the low-pass frequency is at 1000 Hz?\n",
    "\n",
    "Hint: Read about nyquist rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:** (type your answer here) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's extract the data for the raw object and take a look at its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_orig = raw_orig.get_data()  # extract the data using method get_data()\n",
    "print('the shape of the data matrix is ', data_orig.shape)  # print the shape (details about .shape bellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: ndarray.shape\n",
    "\n",
    "* You can get the shape of a numpy array by `.shape`. For example, if `x` is a 2-D numpy array with dimensions $5\\times 10$, `x.shape` returns a tuple equal to `(5, 10)`. You can refer to the first and second dimensions by `x.shape[0]` and `x.shape[1]`.\n",
    "\n",
    "* You can read about tuples in google, for example <a href='https://www.geeksforgeeks.org/tuples-in-python/'>here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: Indexing in Python\n",
    "In Python (like some other languages), indexing of arrays starts with 0.\n",
    "\n",
    "Each member of an array has its own index. Indexing can be from left to right starting from 0 or from right to left from -1:\n",
    "\n",
    "    x = [1, 2, 3, 4, 5]\n",
    "    idx  0  1  2  3  4\n",
    "    idx -5 -4 -3 -2 -1\n",
    "\n",
    "It is important to note that index -4 is exactly the same as index 1 for Python in this example. Based on this negative indexing, you can get the last elemtns of an array or a list by index -1, e.g. `x[-1]`.\n",
    "    \n",
    "\n",
    "Besides, if we want to extract a part of a matrix, we don't have to give any steps if we choose the order of the indexes from left to right, unless we want a step bigger than one. the general syntax is `x[start:end:step]`\n",
    "\n",
    "> `x[0:3]` returns `[1, 2, 3]` corresponding to indices `0, 1, 2`\n",
    "    \n",
    "> `x[0:5:2]` returns `[1, 3, 5]` corresponding to indices `0, 2, 4`\n",
    "    \n",
    "But if our indexes are from right to left, we must give the step -1 or a smaller negative integer. \n",
    "\n",
    "> `x[-2:-5:-1]` returns `[4, 3, 2]`\n",
    "    \n",
    "It is also worth mentioning that Python will continue to one index before the given index. For example 0:3 includes the indices 0, 1, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 2:**\n",
    "\n",
    "* How long is the duration of the recording?\n",
    "  \n",
    "  Hint: You can either use the `_times` attribute of `raw_orig` or use the number of samples and sampling rate to compute the duration of the recording.\n",
    "\n",
    "\n",
    "* How many channels does the recording have?\n",
    "\n",
    "**YOUR ANSWER:**  (type your answer in the cell below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE COMPLETED BY STUDENTS  -------------------\n",
    "# ANSWER TO EXERCISE 2\n",
    "duration_1 = ? # take the last element of _times attribute of raw_orig\n",
    "duration_2 = ? # number of samples is equal to sampling rate multiplied by the duration in seconds. \n",
    "# Now you have the sampling rate and the number of samples, compute the duration.\n",
    "number_of_channels = ? # You have this value in info attribute of raw class\n",
    "#---------------------------------------------------\n",
    "print('Using the _times attribute, the duration of the recording is: ', duration_1/60, '(min)')\n",
    "print('Using the number of smaples and sampling rate, the duration of the recording is: ', duration_2/60, '(min)')\n",
    "print('Number of channels = ', number_of_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling rate of our data is 2500Hz. Based on Nyquist theorem, this sampling frequency can let us reconstruct up to 1250Hz. If the activity of our interest has a maximum frequency of $f_{max}$, we can reduce the sampling rate to at least $2f_{max}$. This helps to reduce the number of data samples and helps to speed up processing steps. \n",
    "\n",
    "In our case, we are working with resting-state data and we are not interested in very high frequency activity. We reduce the sampling rate to 250Hz. We do so using the `resample` method of the raw object. Note that the `resample` function of `scipy.signal` can be also used in case you don't want to use MNE functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resamp = raw_orig.copy()\n",
    "raw_resamp.resample(sfreq=250)  # resample data to 250Hz.\n",
    "# raw_resamp.save(subject + '-resample-raw.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_resamp = mne.io.read_raw_fif(subject + '-resamp-raw.fif')  # read the saved version resampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the number of samples of the resampled data and compare it with the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of samples of resampled data = ', len(raw_resamp._times))\n",
    "print('number of samples of original data = ', len(raw_orig._times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we decreased the sampling rate from 2500Hz to 250Hz (i.e. 1/10), and the number of samples of resampled data are also 1/10 of the number of samples of the original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: the copy() method\n",
    "\n",
    "While some methods of the classes are applied to the object directly, some other make a copy of the object and make the changes on the copy. In the latter case, the original object does not change; however, in the former case, the original object changes. In order to make a copy of an object and keep the original object untouched, the method `copy()` is defined and used for many classes. \n",
    "\n",
    "In the very example in the cell above for resampling: the method `resample` of raw class is applied on the object directly. Therefore, if we do not use the `copy()` method to generate a copy of the `raw_orig` object, after the resampling, the `raw_orig` variable changes. In this tutorial, we want to keep all the versions of data so that we can refer to them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever there are events happening during the recording, those events should be saved in the data structure. Why? Because we need to correspond their occurrence to our data samples. These events may be stimuli (event-related activity) or in our case the *notification* of closing and opening the eyes. The onset and duration of these events are saved in the `_annotations` attribute of the raw object. The function `events_from_annotations` from the mne library extracts the events from a raw object. We use this event matrix later for extracting the data related to EC condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_ = mne.events_from_annotations(raw_resamp)  # extract the events\n",
    "print(events_)\n",
    "events_mat = events_[0]  # save the information of the onset and description of the events in a new variable for the later usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to exclude the EOG channels for the further analysis. The `pick` method of the raw class helps to select the parts using `pick_types` function. So, we omit the VEOG channels by marking it as a bad channel and then excluding the bad channels from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resamp.info['bads'] = ['VEOG']  # add the VEOG channel to the bad channel list of raw_resamp\n",
    "picks = mne.pick_types(raw_resamp.info, meg=False, eeg=True, exclude='bads', chpi=True)  # select the properties that we wanna select form raw_resamp. We want EEG channels and to exclude the bad channels.\n",
    "raw1 = raw_resamp.copy()  # raw1 will include the resampled data with VEOG channel excluded.\n",
    "raw1.pick(picks=picks)  # Select the desired properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we loaded does not contain the channel locations. If the channel locations are measured during the recording, we should read them and put them inside the raw object. Here, we use the standart channel locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1005')  # get the standard montage\n",
    "raw1.set_montage(montage)  # set the montage of raw1 to the standard one\n",
    "raw1.set_eeg_reference(projection=True)  # average referencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take another look at the info attribute of the raw object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw1.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare `raw1.info` and `raw_orig.info`, you see that after adding the channel locations, a new field, `'dig'`,  is added to the info attribute of `raw1`. the `'dig'` field contains the information about the location of the sensors and other important head points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Artifacts\n",
    "\n",
    "### 2.1. Power-line noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps of screening EEG data are to look at the power spectral density (PSD) of data and then the time series of data. Let's take a look at the PSD of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "freq_res = 1  # frequency resolution\n",
    "nfft = (2 ** np.ceil(np.log2(raw1.info['sfreq'] / freq_res))).astype(int)  # number of fast fourier transform (fft) points\n",
    "raw1.plot_psd(fmin=0, fmax=120, n_fft=nfft, picks='all')  # calculate and plot PSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line in the figure above represents the PSD of one channel. The raw class provides us with the nice visualization tool for PSD in the method `plot_psd`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first noise component that is clear already on the PSD is the power-line noise. This noise is at 50Hz in Europe and 60Hz in the US. Therefore, based on the place of recording the frequency of power-line noise may change. You can see the little bumps at 50Hz. Look at the PSD of one of the channels. Here, instead of using the built-in MNE method for computing PSD, we use the `scipy.signal.welch` function, which is the function that MNE uses as well. `scipy.signal.welch` computes the PSD of the input multi-channel signal. The PSD is traditionally plotted in dB scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hf.plot_psd(raw1.get_data()[54, :]*1e6, raw1.info['sfreq'], freq_res=1, f_max=120) # plot the psd\n",
    "ax.arrow(x=np.array([50]), y=4, dx=0, dy=-10, color='red',\n",
    "                     width=0.1, head_width=3, length_includes_head=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should filter the power-line noise. Based on the content of data we can take two approaches:\n",
    "* Low-pass/band-pass filtering with cut-off frequency lower than 50Hz: this approach is useful when we don't expect our data to contain information in high frequency bands, or we aren't interested in such information. This approach also helps to reduce the muscle artifact, which has a high frequency content.\n",
    "* Notch-filter at 50Hz: A notch filter passes the signal at all frequencies except the specified frequency band. If we notch filter at 50Hz, the rest of the signal content is not touched. This approach should be followed when the signal of interest has high-frequency components (e.g. high gamma waves) \n",
    "\n",
    "Below, we look at the frequency-response of two filters. First we start with the bandpass filtering of one channel (P2): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "fs =  raw1.info['sfreq']  # sampling frequency\n",
    "data1_bp = hf.bandpass_filter_raw_plot(raw1.get_data()[54:55, :], fs, 1, 45)\n",
    "data2 = np.append(raw1.get_data()[54:55, :], data1_bp, axis=0)  # concatenate the original and filtered data, so that we can take a look at their PSDs together\n",
    "ax = hf.plot_psd(data2*1e6, fs, freq_res=1, f_max=55) # plot the psd\n",
    "ax.legend({'original data', 'filtered data'})\n",
    "plt.title('PSD of channel P2 before and after bandpass filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see the signal content at frequencies higher than 45 is attenuated dramatically. Now let's look at a notch filter at 50Hz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = raw1.info['sfreq']\n",
    "data1_n = hf.notch_filter_raw_plot(raw1.get_data()[54:55, :], fs, 50)\n",
    "data2 = np.concatenate((raw1.get_data()[54:55, :], data1_n, data1_bp), axis=0)\n",
    "ax = hf.plot_psd(data2*1e6, fs, freq_res=1, f_max=55)\n",
    "plt.title('PSD of channel P2 before and after notch and bandpass filtering')\n",
    "ax.legend(['original', 'notch', 'bandpass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the notch filter only omits the signal content at the specified frequency. \n",
    "\n",
    "For the rest of this tutorial we bandpass filter the signal, because here we have resting-state data and we aren't interested in higher frequency content. In the following, we use the built-in method of raw class for filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iir_params = dict(order=2, ftype='butter')  # parameters of the iir filter: butterwirth bandpass filter order 4. \n",
    "raw1.filter(l_freq=1, h_freq=45, method='iir', iir_params=iir_params)  # l_freq is the low-frequency cut-off, h_freq is the high-frequency cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the new PSD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "freq_res = 1\n",
    "nfft = (2 ** np.ceil(np.log2(raw1.info['sfreq'] / freq_res))).astype(int)\n",
    "raw1.plot_psd(fmin=0, fmax=45, n_fft=nfft, picks='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting EC condition data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, this data consists of segments of eyes closed (EC) and eyes open (OP) conditions. We want to use EC condition. Therefore, we should cut the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we separate the EC and EO conditions?\n",
    "\n",
    "* In EO condition the amount of eye-related artifacts is much more. Therefore, if we combine the EC and EO, we may miss some noise sources from EO, since those are not pronounced in EC. Or we may remove a lot variance from EC data, since a noise source from EO condition has driven inpendent component analysis (ICA, method used for denoising).\n",
    "* These two conditions have different functional implications. For example, in EC condition alpha source signals are much stronger, in EO condition there is visual input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `extract_ec_condition` from the help funcitons of this tutorial selects the data related to this condition and returns a raw object which only includes the EC condition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = hf.extract_ec_condition(raw1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you are interested to see how we extract the EC condition data, you can continue with this part. I encourage you to do so, because it helps to improve your programming skills and also to get to know the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 3:** Complete the code below.\n",
    "\n",
    "Hint: you can go back to section 1, where we introduced the events and computed `events_mat` of the raw class. There you see that the first column of this matrix is the stimulus onset and the 3rd column of it is the stimulus description. We want to extract these two columns and put them into the new variables `annot_onset` and `annot_description`. In order to remind you of how the indexing in Python works, you can refer again to the *Coding Detail: Indexing in Python** on top of the notebook - it is right after exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE COMPLETED BY STUDENTS ------------------\n",
    "# ANSWER TO EXERCISE 3\n",
    "annot_onset = ? \n",
    "annot_description = ? \n",
    "# ---------------------------------------------\n",
    "print(np.unique(annot_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EC condition is marked with 210, while EO has the marker 200. Therefore, as far as a sample has marker 210, it is an EC condition. We want to separate the EC data segments. In order to find the onset of the EC condition, we first mark all the 210 events as one and all the other events as zero. With this trick, we can detect where the first 210 event happens and find the onset of EC condition. \n",
    "\n",
    "* First we make an array of zeros with the same shape as annot_description, call it ec_array.\n",
    "* Then whereever annot_description is 210, we put a 1 in ec_array.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: numpy.zeros\n",
    "\n",
    "* You can make an array of zeros using <a href='https://numpy.org/doc/stable/reference/generated/numpy.zeros.html'>`numpy.zeros`</a>. There are similar ways of making arrays of ones and empty array using `numpy.ones` and `numpy.empty`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 4**: complete the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE COMPLETED BY STUDENTS ------------------\n",
    "# ANSWER TO EXERCISE 4\n",
    "ec_array = ?  # build an array of zeros with the same size as annot_description\n",
    "# ---------------------------------------------\n",
    "\n",
    "ec_array[annot_description==210] = 1\n",
    "# %matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(ec_array)\n",
    "plt.xlabel('sample number')\n",
    "plt.ylabel('Condition (1= EC - 0=EO)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see in the figure above is where (in which sample point) the EC condition starts and ends. Now we should do an *edge detection* to find where `ec_array` is one. If you think of it algorithmically, you see that if we subtract the `ec_array` value of each sample from its previous sample, we get zero at all samples except at the onsets of EC condition we get 1 and at the end of the EC condition we get -1. <a href='https://numpy.org/doc/stable/reference/generated/numpy.diff.html'>np.diff</a> computes the difference of the elements of its input array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_array_diff = np.diff(ec_array) \n",
    "ind_start = np.where(ec_array_diff == 1)[0] + 1  # find the onset of EC -> where ec_array_diff is 1\n",
    "ind_end = np.where(ec_array_diff == -1)[0] + 1   # find the end of EC -> where ec_array_diff is -1\n",
    "if ind_end.shape[0] != ind_start.shape[0]:\n",
    "    ind_end = np.append(ind_end, ec_array_diff.shape[0])\n",
    "plt.figure()\n",
    "plt.plot(ec_array)\n",
    "plt.plot(ind_start, np.ones(ind_start.shape), 'r*')\n",
    "plt.plot(ind_end, np.zeros(ind_end.shape), 'g*')\n",
    "\n",
    "onset_ec = annot_onset[ind_start]  # the sample corresponding to onset of EC\n",
    "duration_ec = annot_onset[ind_end] - onset_ec  # the duration of corresponding EC\n",
    "plt.xlabel('sample number')\n",
    "plt.ylabel('Condition (1= EC - 0=EO)')\n",
    "plt.legend(['events', 'onset of EC', 'end of EC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we detected the EC condition duration and starting samples, we can segment our data and extract these condition's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw1.get_data()  \n",
    "ind_start_data = onset_ec\n",
    "ind_end_data = annot_onset[ind_end]\n",
    "n_ec_segments = ind_start.shape[0]\n",
    "data_new = np.empty((data.shape[0],0))\n",
    "for i_seg in range(n_ec_segments):\n",
    "    data_new = np.append(data_new, data[:, ind_start_data[i_seg]:ind_end_data[i_seg]], axis=1)\n",
    "print('duration of data=' + str(data_new.shape[1]/raw1.info['sfreq']/60) + ' (s)')\n",
    "raw = mne.io.RawArray(data_new, raw1.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that we have almost 8min of EC data. Additionally, you see that we can make a new raw object using `mne.io.RawArray` if we have the data matrix (with the shape channel $\\times$ sample) and the info structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='gray'>\n",
    "\n",
    "#### Coding Detail: for loop\n",
    "\n",
    "In order to build a for loop you need a counter that *counts* the iterations. Counting does not mean that it has to go from 0 to n, but it means that any iteration should be identified using a counter value. The general for loop structure is like:\n",
    "\n",
    "    for k in ...:\n",
    "        # Do sth\n",
    "        \n",
    "In the above code, k is the counter and should go through some values in the iterations. There are different ways of producing these values based on how we wanna count the iterations. Here are some of the possible ways:\n",
    "\n",
    "* range. it is used when you want to generate some integer values and go through them in the iterations. Besides many other websites, you can learn about it <a href='https://www.geeksforgeeks.org/python-range-function/'>here</a>.\n",
    "* enumerate. it is used when you want to loop over a list or an array. check <a href='https://book.pythontips.com/en/latest/enumerate.html'>here</a> or <a href='https://www.geeksforgeeks.org/enumerate-in-python/'>here</a> for example.\n",
    "* zip. it is used to loop over an aggregation of multiple arrays or lists. check <a href='https://www.geeksforgeeks.org/zip-in-python/'>here</a> or <a href='https://www.geeksforgeeks.org/zip-in-python/'>here</a> for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep the track of where a new segment starts we add the annotations to the new raw object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw._annotations = mne.Annotations(onset_ec, duration_ec, ['new ec segment'] * n_ec_segments, \n",
    "                                     orig_time=raw.info['meas_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = mne.io.read_raw_fif(subject + '-ec-raw.fif')  # read the saved version of the data with only EC condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Artifacts: Bad segments and channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned the power-line noise by filtering. That was easy! ;-) The other noise sources are a bit harder to remove because they are entangled with brain signals and we want to do our best not to remove the precious brain activities, while cleaning the artifacts. This may look impossible at the first glance. But thanks to signal processing tools, we are able to *blindly* separate a lot of noise sources from our data effectively. Why *blindly*? Because we do not have a lot of information about the artifact sources; therefore, those source separation methods that separate signal sources without specific information about individual sources are called *blind source separation (BSS)* methods. One of the most famous BSS methods is called *Independetn Component Analysis (ICA)*. This is one of the most common words that you will here while working with neuroimaging data. ICA assumes that the source signals have non-Gaussian distribution and this is its only assumption about the sources. You see how *blind* it is?! ;-)\n",
    "\n",
    "So, we want to resume with our artifact cleaning using ICA. We will clean eye-blinks, eye-movement, heart beats, and muscle artifact using ICA. Honestly, although it has been many years that I work with BSS methods and I am familiar with details of many of them, I still find it fascinating how genius these methods are, although being blind. Or maybe those BSS methods aren't genius, but the signal sources have a fascinating non-Gaussian structure!\n",
    "\n",
    "In order to help ICA to detect the noise sources, we should remove the extremely noisy data segments or channels. These extremely noisy segments or channels (which are usually due to muscle artifact) can bias ICA. Therefore, the first step of data cleaning is always to look at the time series and mark those bad segments and bad channels. This is actually a trade-off: if you remove a lot of bad segments/channels, you loose also your data. It is like throwing the baby out with the bathwater! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to look at the PSD and see if there is a channel that must be excluded, based on the evidences you see in the PSD. If so, keep it in mind to reject it later, or just add it to the `bads` field of info attribute of raw object. The evidences in PSD that may make you exclude a channel can be \n",
    "\n",
    "* A lot of high-frequency noise. In such a case the PSD of the channel is kind of flying. It means that in the higher frequencie, instead of decaying, it is either straight or going up. We know that muscle artifact has high frequency. Therefore, if a channel is extremely contaminated by muscle noise, it should be excluded.\n",
    "\n",
    "* The PSD of the channel is lying in a very lower or higher level in comparison to that of other channels.\n",
    "\n",
    "In the figure below, some people may find PO10 a noisy channel, I would keep it and decide later. I suggest you to be conservative regarding excluding channels. You can click on the interactive graph below and identify the flying PSD of channel PO10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_res = 1\n",
    "nfft = (2 ** np.ceil(np.log2(raw.info['sfreq'] / freq_res))).astype(int)\n",
    "raw.plot_psd(fmin=0, fmax=45, n_fft=nfft, picks='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['bads'] = [] # here you can put a list of channel names that should be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can mark bad channels and segment using the interactive window that MNE opens for us using the `plot()` method of raw class. In order to select bad channels, you only have to click on the name of the channel at the left side of the figure, or on the time series of the channel. In order to mark bad segments, you should go to annotation mode. Press Help button to see how you can go to annotation mode. For example, for mac users, you have to press a, then type the new label name starting with BAD, let' say \"BAD_SEGMENT\" and add the label. Then left click on the starting point of the bad segment and drag to its end. You see that the data segment is highlighted with red. In the video below, you can see how it works on my mac. Try not to exclude a lot, but exclude the segments where an extreme muscle activity is seen. Eye blinks can be removed with ICA later. More in <a href='https://mne.tools/stable/auto_tutorials/preprocessing/plot_20_rejecting_bad_data.html#sphx-glr-auto-tutorials-preprocessing-plot-20-rejecting-bad-data-py'>this MNE tutorial</a>. <a href='https://mne.tools/stable/auto_tutorials/raw/plot_30_annotate_raw.html#sphx-glr-auto-tutorials-raw-plot-30-annotate-raw-py'>This</a> may be also helpful.\n",
    "\n",
    "    \n",
    "> **Note:** If you are using the jupyter hub and `%matplotlib notebook`, it seems that that this option won't work for you!! Then, you have to load the raw object that I saved with bad segment annotations:\n",
    "    \n",
    "        raw = mne.io.read_raw_fif(subject + '-annotation-raw.fif')\n",
    "> and then plot it and only look at the bad segments I have marked. You can look at the bad segments by sliding the grey square a long the time axis:\n",
    "    \n",
    "        raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"video1.mov\", width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in case you are using %matplotlib notebook, read the data with bad segment annotations and then continue\n",
    "# if you are on your local machine with %matplotlib tk, do not run this line since you will loose your raw varibale\n",
    "# and it will be replace by the one I saved with the annotations.\n",
    "raw = mne.io.read_raw_fif(subject + '-annotation-raw.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib tk\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw._annotations)  # check the annotations\n",
    "# raw.save(subject + '-annotation-' + '-raw.fif')  # I marked the bad segments and saved it already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have marked the bad segments once, you may load it and compare it with yours. Note that if you wanna compare, load it in a variable with a name different than `raw` so that your raw object is not replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = mne.io.read_raw_fif(subject + '-annotation-raw.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] https://mne.tools/stable/index.html\n",
    "\n",
    "[2] Babayan, A. et al. (2019) A mind-brain-body dataset of MRI, EEG, cognition, emotion, and peripheral physiology in young and old adults. Sci. Data. 6:180308 https://doi.org/10.1038/sdata.2018.308.\n",
    "\n",
    "[3] https://mne.tools/stable/auto_tutorials/io/plot_20_reading_eeg_data.html#brainvision-vhdr-vmrk-eeg\n",
    "\n",
    "[4] Maximilien Chaumon, Dorothy V.M. Bishop, Niko A. Busch (2015) A practical guide to the selection of independent components of the electroencephalogram for artifact correction, Journal of Neuroscience Methods, Volume 250, pp 47-63, https://doi.org/10.1016/j.jneumeth.2015.02.025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
